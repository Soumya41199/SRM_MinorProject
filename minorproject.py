# -*- coding: utf-8 -*-
"""MINORPROJECT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Kt4PR971lhC7XT7wC_3nsrxmxV1mOiw4

# IMPORTING THE REQUIRED LIBRARIES
"""

# Commented out IPython magic to ensure Python compatibility.
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

df = pd.read_csv('/content/diabetes.csv')

"""#DATA PREPROCESSING"""

df.head()

df.shape

df.info()

df.isnull().sum()

df['Outcome'].unique()

df['Outcome'].value_counts()

sns.countplot(df['Outcome'],label="count")

df.describe()

sns.pairplot(data = df, hue = 'Outcome')
plt.show()

sns.set_style('whitegrid')
sns.countplot(x='Outcome',hue='Outcome',data=df,palette='cubehelix')

plt.scatter(x='Outcome',y='Age',data=df)
plt.ylabel('Age')
plt.xlabel('Outcome')

sns.distplot(df['BloodPressure'],kde=False,color='red',bins=20)

sns.jointplot(x='Age',y='BloodPressure',data=df)

"""# FINDING CORRELATION BETWEEN FEATURES"""

plt.figure(figsize=(20,12))
sns.heatmap(df.corr(),annot=True)

df.corr()

del df['SkinThickness']

df.head()

"""# CHECKING FOR TRUE/FALSE RATIO"""

num_obs = len(df)
num_true = len(df.loc[df['Outcome'] == 1])
num_false = len(df.loc[df['Outcome'] == 0])
print("Number of True cases:  {0} ({1:2.2f}%)".format(num_true, (num_true/num_obs) * 100))
print("Number of False cases: {0} ({1:2.2f}%)".format(num_false, (num_false/num_obs) * 100))

"""# SPLITTING THE DATASET

"""

from sklearn.model_selection import train_test_split

feature_colnames = ['Pregnancies','Glucose','BloodPressure','Insulin','BMI','DiabetesPedigreeFunction','Age']
predict_colname = ['Outcome']

X = df[feature_colnames].values
y = df[predict_colname].values
split_test_size = 0.2
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = split_test_size,random_state=42)

"""Checking for split done correctly"""

print("{0:0.2f}% in training set".format((len(X_train)/len(df.index)) * 100))
print("{0:0.2f}% in test set".format((len(X_test)/len(df.index)) * 100))

df.head()

"""#DEALING WITH NULL VALUES

"""

from sklearn.impute import SimpleImputer #imputing is used to replaces null values with numeric values

# For all readings == 0, impute with mean
fill_0 = SimpleImputer(missing_values=0,strategy="mean")

X_train= fill_0.fit_transform(X_train)
X_test = fill_0.fit_transform(X_test)

"""#1.IMPLEMENTATION OF RANDOM FOREST CLASSIFIER

"""

from sklearn.ensemble import RandomForestClassifier
rf_model = RandomForestClassifier(random_state=42) 
rf_model.fit(X_train,y_train.ravel())

"""IMPLEMENTATION ON TRAINING DATA

"""

from sklearn import metrics
rf_predict_train = rf_model.predict(X_train)
print("Accuracy: {0:.3f}".format(metrics.accuracy_score(y_train,rf_predict_train)))
print()

"""IMPLEMENTATION ON TESTING DATA"""

rf_predict_test = rf_model.predict(X_test)
print("Accuracy:{0:.4f}".format(metrics.accuracy_score(y_test,rf_predict_test)))
print()

print("CONFUSION MATRIX")
print(metrics.confusion_matrix(y_test,rf_predict_test))

sns.heatmap(confusion_matrix(y_test,rf_predict_test),annot=True)

print("Classification Report")
print(metrics.classification_report(y_test, rf_predict_test))

"""# IMPLEMENTING SUPPORT VECTOR CLASSIFIER"""

from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix

svc = SVC()
y_predict = svc.fit(X_train, y_train.ravel()).predict(X_test)

print("Accuracy on training set: {: .2f}".format(svc.score(X_train, y_train)))
print("Accuracy on test set: {: .2f}".format(svc.score(X_test, y_test)))

print(confusion_matrix(y_test, y_predict))

sns.heatmap(confusion_matrix(y_test,y_predict),annot=True)

print(classification_report(y_test, y_predict))

"""# IMPLEMENTING LOGISTIC REGRESSION"""

from sklearn.linear_model import LogisticRegression

lr_model = LogisticRegression(C=0.7, random_state=42)
lr_model.fit(X_train, y_train.ravel())
lr_predict_test = lr_model.predict(X_test)

print("Accuracy: {0:.3f}".format(metrics.accuracy_score(y_test, lr_predict_test)))

print(metrics.confusion_matrix( y_test,lr_predict_test,labels=[0,1]))

print(classification_report(y_test,lr_predict_test,labels=[0,1]))

sns.heatmap(confusion_matrix(y_test,lr_predict_test),annot=True)